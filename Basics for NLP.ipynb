{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06ac77a9",
   "metadata": {},
   "source": [
    "# <center>Basics for Natural Learning Processing (NLP)<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4912f4",
   "metadata": {},
   "source": [
    "Natural Language Processing (NLP) is a subfield of artificial intelligence that focuses on the interaction between humans and computers using natural language. It empowers machines to understand, interpret, and generate human language, enabling applications like speech recognition, machine translation, sentiment analysis, and more. In this notebook, we will delve into the basics of NLP and provide practical code examples to help beginners grasp the fundamental concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b7e20d",
   "metadata": {},
   "source": [
    "# 1. Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca53bc26",
   "metadata": {},
   "source": [
    "Tokenization is the process of breaking down a sentence or paragraph into smaller units called tokens. These tokens can be words, phrases, or characters. In Python, the NLTK library provides essential functions for tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f60f238f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c41e0da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'Language', 'Processing', 'is', 'fascinating', '!']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"Natural Language Processing is fascinating!\"\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bdef9f",
   "metadata": {},
   "source": [
    "# 2. Stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592618a5",
   "metadata": {},
   "source": [
    "Stop words are common words like \"the,\" \"is,\" \"and,\" which do not carry much meaning in the context of NLP. They are often removed from text to improve processing efficiency and focus on essential words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c116611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "140d6342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'Language', 'Processing', 'fascinating', '!']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "print(filtered_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590512e8",
   "metadata": {},
   "source": [
    "# 3. Stemming and lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47d4eae",
   "metadata": {},
   "source": [
    "Stemming and lemmatization are techniques used to reduce words to their root or base form. They help in reducing vocabulary size and normalizing text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c9da525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f06e58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed: ['natur', 'languag', 'process', 'fascin', '!']\n",
      "Lemmatized: ['Natural', 'Language', 'Processing', 'fascinating', '!']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "stemmed_words = [stemmer.stem(word) for word in filtered_tokens]\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "\n",
    "print(\"Stemmed:\", stemmed_words)\n",
    "print(\"Lemmatized:\", lemmatized_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d0050e",
   "metadata": {},
   "source": [
    "# 4. Part-of-Speech (POS) Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331f51da",
   "metadata": {},
   "source": [
    "POS tagging is the process of assigning grammatical tags to each word in a sentence, such as noun, verb, adjective, etc. The NLTK library provides functions for POS tagging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc7a49ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('fascinating', 'NN'), ('!', '.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "\n",
    "pos_tags = pos_tag(filtered_tokens)\n",
    "print(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75813dea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural PROPN\n",
      "Language PROPN\n",
      "Processing PROPN\n",
      "is AUX\n",
      "fascinating ADJ\n",
      "! PUNCT\n"
     ]
    }
   ],
   "source": [
    "# spacy reults are more accurate here.\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Natural Language Processing is fascinating!\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f728eb",
   "metadata": {},
   "source": [
    "# 5. Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553b9a28",
   "metadata": {},
   "source": [
    "NER is the task of identifying named entities in a text, such as names of people, organizations, locations, etc. The spaCy library provides an efficient way to perform NER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1993d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Processing ORG\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "text = \"Natural Language Processing is fascinating!\"\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "doc = nlp(text)\n",
    "\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfbb5d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andrew NG PERSON\n"
     ]
    }
   ],
   "source": [
    "text = \"Andrew NG is brilliant!\"\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "doc = nlp(text)\n",
    "\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e5ad2d",
   "metadata": {},
   "source": [
    "*End Note:*<br>\n",
    "Natural Language Processing is a captivating field that empowers machines to understand and work with human language. In this article, we covered essential NLP concepts, including tokenization, stop words removal, stemming, lemmatization, POS tagging, and Named Entity Recognition. By leveraging the power of NLP, developers can build applications that analyze, interpret, and generate human language, revolutionizing how we interact with computers and technology. Happy coding and exploring the vast world of NLP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
